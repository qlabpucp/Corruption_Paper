{"cells":[{"cell_type":"markdown","id":"c16703ef-3ce1-4fb4-a5f4-9c50c26157c7","metadata":{"id":"c16703ef-3ce1-4fb4-a5f4-9c50c26157c7"},"source":["# BASE 0 - CA"]},{"cell_type":"markdown","id":"77ea7de5-2163-4eed-8420-26f0de6737ec","metadata":{"id":"77ea7de5-2163-4eed-8420-26f0de6737ec"},"source":["Information:\n","\n","* Database: base 0\n","* Predicted variable: Corrupción Amplia\n","* Predictor variables: Only SIAF and Canon\n","* Type of prediction: Clasification\n","* Period of training: 2016-2020"]},{"cell_type":"markdown","id":"1aca0c1c-50f7-4f75-b07e-83cea7238d5b","metadata":{"id":"1aca0c1c-50f7-4f75-b07e-83cea7238d5b"},"source":["## 1. Cargar librerías, módulos y datos"]},{"cell_type":"code","execution_count":49,"id":"4ca2434c-6b68-4561-89c9-cd8044733a29","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703821356689,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"4ca2434c-6b68-4561-89c9-cd8044733a29"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings( 'ignore' )"]},{"cell_type":"code","execution_count":50,"id":"daea9755-b514-4eac-a8b3-97ab86131b45","metadata":{"executionInfo":{"elapsed":427,"status":"ok","timestamp":1703821357112,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"daea9755-b514-4eac-a8b3-97ab86131b45"},"outputs":[],"source":["import pandas as  pd\n","import numpy as np\n","import pickle\n","import joblib\n","from importlib.machinery import SourceFileLoader"]},{"cell_type":"code","execution_count":51,"id":"c840acee-e68c-4a8f-a4a4-772d9c978ea4","metadata":{"executionInfo":{"elapsed":639,"status":"ok","timestamp":1703821357749,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"c840acee-e68c-4a8f-a4a4-772d9c978ea4"},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","from imblearn.combine import SMOTETomek\n","from imblearn.over_sampling import RandomOverSampler\n","from collections import Counter"]},{"cell_type":"code","execution_count":52,"id":"c7a7263d-7a53-4cfd-a311-f770ce2445f8","metadata":{"executionInfo":{"elapsed":299,"status":"ok","timestamp":1703821358043,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"c7a7263d-7a53-4cfd-a311-f770ce2445f8"},"outputs":[],"source":["from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, matthews_corrcoef\n","from xgboost import XGBRegressor, XGBClassifier\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":53,"id":"a121d286","metadata":{},"outputs":[],"source":["from econml.grf import RegressionForest\n","from lightgbm import LGBMClassifier"]},{"cell_type":"code","execution_count":54,"id":"1voWOj7f4uXi","metadata":{"executionInfo":{"elapsed":992,"status":"ok","timestamp":1703821377457,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"1voWOj7f4uXi"},"outputs":[],"source":["fun = SourceFileLoader( 'funciones', r'..\\..\\..\\code\\modules\\funciones.py' ).load_module()\n","vn  = SourceFileLoader( 'variables_nombres', r'..\\..\\..\\code\\modules\\variables_nombres.py' ).load_module()"]},{"cell_type":"code","execution_count":55,"id":"32f68f2d-0dd3-416b-89a3-16d3ccf44eee","metadata":{"executionInfo":{"elapsed":6325,"status":"ok","timestamp":1703821383779,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"32f68f2d-0dd3-416b-89a3-16d3ccf44eee"},"outputs":[],"source":["from sklearn.datasets import make_classification\n","import pandas as pd\n","\n","# Generar un dataset de clasificación binaria\n","X, y = make_classification(n_samples=100, n_features=20, n_classes=2, random_state=42)\n","\n","# Convertir a DataFrame para mejor manejo\n","x_train = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(1, 21)])\n","y_train = pd.DataFrame(y)\n","y_train = y_train.rename( columns = {0:'target'})"]},{"cell_type":"markdown","id":"3f504639-4a7d-4df1-ac15-96b4618e06db","metadata":{"id":"3f504639-4a7d-4df1-ac15-96b4618e06db"},"source":["## 2. Realizar la partición en conjunto de entrenamiento y prueba"]},{"cell_type":"code","execution_count":56,"id":"e45eaf74","metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split( x_train,\n","                                                     y_train,\n","                                                     test_size    = 0.3,\n","                                                     random_state = 2023 )"]},{"cell_type":"markdown","id":"52dd3078-aa0b-4593-b2b5-9763591a7991","metadata":{"id":"52dd3078-aa0b-4593-b2b5-9763591a7991"},"source":["## 3. Implementar métodos de muestreo"]},{"cell_type":"markdown","id":"e5f54c5f-fd9c-4c3a-9368-ce7008e46136","metadata":{"id":"e5f54c5f-fd9c-4c3a-9368-ce7008e46136"},"source":["Se implementan los métodos SMOTE, SMOTE Tomek-Links y Naive Random Oversampling"]},{"cell_type":"code","execution_count":57,"id":"f60399f2-ef36-4b0b-b246-514bd58ff20c","metadata":{"executionInfo":{"elapsed":6242,"status":"ok","timestamp":1703821390018,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"f60399f2-ef36-4b0b-b246-514bd58ff20c"},"outputs":[],"source":["x_train_s, x_train_st, x_train_nro, y_train_s, y_train_st, y_train_nro = fun.resampling( x_train, y_train )"]},{"cell_type":"code","execution_count":58,"id":"619255c9","metadata":{},"outputs":[],"source":["x_train.name = 'x_train_o'\n","x_train_s.name = 'x_train_s'\n","x_train_st.name = 'x_train_st'\n","x_train_nro.name = 'x_train_nro'"]},{"cell_type":"code","execution_count":59,"id":"zXY1E6zVmtrr","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1703821390018,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"zXY1E6zVmtrr","outputId":"f50a504e-65ce-4571-93a2-8896a8a87b58"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>observaciones</th>\n","      <th>variables</th>\n","      <th>Nro. No</th>\n","      <th>Nro. Si</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Original</th>\n","      <td>70.0</td>\n","      <td>20.0</td>\n","      <td>35.0</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>SMOTE</th>\n","      <td>70.0</td>\n","      <td>20.0</td>\n","      <td>35.0</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>SOMTE Tomek</th>\n","      <td>66.0</td>\n","      <td>20.0</td>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","    </tr>\n","    <tr>\n","      <th>NRS</th>\n","      <td>70.0</td>\n","      <td>20.0</td>\n","      <td>35.0</td>\n","      <td>35.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             observaciones  variables  Nro. No  Nro. Si\n","Original              70.0       20.0     35.0     35.0\n","SMOTE                 70.0       20.0     35.0     35.0\n","SOMTE Tomek           66.0       20.0     33.0     33.0\n","NRS                   70.0       20.0     35.0     35.0"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["check_data      = np.zeros( ( 4, 4 ) )\n","\n","check_data[ 0 ] = [ x_train.shape[ 0 ], x_train.shape[ 1 ],\n","                    y_train.value_counts()[ 0 ], y_train.value_counts()[ 1 ] ]\n","\n","check_data[ 1 ] = [ x_train_s.shape[ 0 ], x_train_s.shape[ 1 ],\n","                    y_train_s.value_counts()[ 0 ], y_train_s.value_counts()[ 1 ] ]\n","\n","check_data[ 2 ] = [ x_train_st.shape[ 0 ], x_train_st.shape[ 1 ],\n","                    y_train_st.value_counts()[ 0 ], y_train_st.value_counts()[ 1 ] ]\n","\n","check_data[ 3 ] = [ x_train_nro.shape[ 0 ], x_train_nro.shape[ 1 ],\n","                    y_train_nro.value_counts()[ 0 ], y_train_nro.value_counts()[ 1 ] ]\n","\n","colnames        = [ 'observaciones', 'variables', 'Nro. No', 'Nro. Si' ]\n","\n","rownames        = [ 'Original',\n","                    'SMOTE',\n","                    'SOMTE Tomek',\n","                    'NRS' ]\n","\n","table_check_data = pd.DataFrame( check_data, columns = colnames )\n","table_check_data.index = rownames\n","table_check_data"]},{"cell_type":"markdown","id":"ee9e3f85-c184-4a9e-b1d4-95e253d4d330","metadata":{"id":"ee9e3f85-c184-4a9e-b1d4-95e253d4d330"},"source":["## 4. Implementar los modelos de clasificación"]},{"cell_type":"code","execution_count":60,"id":"065a3d42-8d6d-4f40-955a-2114cc19b13b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703821390018,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"065a3d42-8d6d-4f40-955a-2114cc19b13b","outputId":"7c2089f7-5e41-42a2-db0c-f42dd6ab577a"},"outputs":[{"name":"stdout","output_type":"stream","text":["4.0\n","6.0\n","8.0\n"]}],"source":["o_20 = 20*x_train.shape[ 1 ]/100\n","o_30 = 30*x_train.shape[ 1 ]/100\n","o_40 = 40*x_train.shape[ 1 ]/100\n","\n","print( o_20, o_30, o_40, sep = '\\n' )"]},{"cell_type":"code","execution_count":61,"id":"244e1546-58aa-4e49-946b-d3a75d03d365","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1703821390018,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"244e1546-58aa-4e49-946b-d3a75d03d365"},"outputs":[],"source":["# models = {\n","\n","#     'Logistic Regression'      : { 'model'      : LogisticRegression( random_state = 2023, n_jobs = -1 ) },\n","\n","#     'Logistic Lasso'           : { 'model'      : LogisticRegressionCV( random_state = 2023, penalty = 'l1', solver = 'saga', n_jobs = -1, Cs = [ 0.001, 0.01, 0.1, 1, 10, 100 ] ) },\n","\n","#     'Logistic Ridge'           : { 'model'      : LogisticRegressionCV( random_state = 2023, penalty = 'l2', solver = 'saga', n_jobs = -1, Cs = [ 0.001, 0.01, 0.1, 1, 10, 100 ] ) },\n","\n","#     'Logistic Elastic Net'     : { 'model'      : LogisticRegressionCV( random_state = 2023, penalty = 'elasticnet', solver = 'saga', l1_ratios = [ 0.5 ], n_jobs = -1, Cs = [ 0.001, 0.01, 0.1, 1, 10, 100 ] ) },\n","\n","#     'Random Forest Classifier' : { 'model'      : RandomForestClassifier( random_state = 2023, n_jobs = -1 ),\n","#                                    'grid_params': { 'n_estimators': [ 250, 500, 1000 ], 'max_depth': [ 10, 20, 30 ], 'max_features': [ 2864, 4295, 5727 ] } },\n","\n","#     'XGboost Classifier'       : { 'model'      : XGBClassifier( random_state = 2023, use_label_encoder = False, objective = 'binary:logistic', verbosity = 0, learning_rate = 0.1, n_jobs = -1 ),\n","#                                    'grid_params': { 'n_estimators': [ 250, 500, 1000 ], 'max_depth': [ 1, 2 ], 'max_features': [ 2864, 4295, 5727 ] } },\n","\n","\n","#     'LGBMClassifier'           : { 'model'      : LGBMClassifier( random_state = 2023, n_jobs = -1 ),\n","#                                    'grid_params': { 'n_estimators': [ 250, 500, 1000 ], 'max_depth': [ 1, 2 ] } },\n","\n","\n","#         }\n","\n","models_regression_forest = {\n","    'Regression Forest' : { 'model'      : RegressionForest( random_state = 2023, n_jobs = -1 ),\n","                            'grid_params': { 'n_estimators': [ 252 ], 'max_depth': [ 10, 15 ] } }\n","        }"]},{"cell_type":"code","execution_count":62,"id":"9e83de3e-5e96-4f03-8ac3-453e40fd7380","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703821390019,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"9e83de3e-5e96-4f03-8ac3-453e40fd7380"},"outputs":[],"source":["models_path  = r'..\\..\\..\\output\\ejecucion_11\\models'\n","results_path = r'..\\..\\..\\output\\ejecucion_11\\results'\n","vars_path    = r'..\\..\\..\\output\\ejecucion_11\\vars'\n","gs_path      = r'..\\..\\..\\output\\ejecucion_11\\gridsearch_results'"]},{"cell_type":"code","execution_count":63,"id":"e6341349-e5db-4ec9-8f8a-a0086ede71d2","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703821390019,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"e6341349-e5db-4ec9-8f8a-a0086ede71d2"},"outputs":[],"source":["x_train_list = [ x_train, x_train_s, x_train_st, x_train_nro ]\n","y_train_list = [ y_train, y_train_s, y_train_st, y_train_nro ]\n","path_list    = [ models_path, results_path, vars_path, gs_path ]"]},{"cell_type":"code","execution_count":64,"id":"fa177cd1-cb95-491c-858b-c30c2d2d5fc5","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703821390019,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"fa177cd1-cb95-491c-858b-c30c2d2d5fc5"},"outputs":[],"source":["sufix   = 'ca'"]},{"cell_type":"code","execution_count":65,"id":"b724ee2a","metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from glob import glob\n","import os\n","from importlib.machinery import SourceFileLoader\n","import xlsxwriter\n","\n","# import variables_nombres as vn\n","# vn  = SourceFileLoader( 'variables_nombres', 'variables_nombres.py' ).load_module()\n","\n","import variables_nombres as vn\n","\n","\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score, matthews_corrcoef, classification_report\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from xgboost import XGBRegressor, XGBClassifier\n","from sklearn.linear_model import Lasso, Ridge, LinearRegression\n","from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n","from sklearn.model_selection import KFold\n","from sklearn.feature_selection import VarianceThreshold\n","\n","import pickle\n","import joblib\n","import matplotlib.pyplot as plt\n","\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.over_sampling import SMOTE\n","from imblearn.combine import SMOTETomek\n","from collections import Counter\n"]},{"cell_type":"code","execution_count":66,"id":"af00f4cd-bd52-4fbd-9a8d-ec981d83325d","metadata":{"executionInfo":{"elapsed":16836099,"status":"ok","timestamp":1703849908175,"user":{"displayName":"A C","userId":"11950158208259960487"},"user_tz":300},"id":"af00f4cd-bd52-4fbd-9a8d-ec981d83325d"},"outputs":[],"source":["def extract_suffix(name):\n","    '''\n","    Objetivo: \n","        - Extrae el sufijo del nombre del conjunto de entrenamiento.\n","          Ejemplo: 'x_train_st' -> 'st'\n","    '''\n","    parts = name.split('_')\n","    if len(parts) > 2:\n","        return '_'.join(parts[2:])\n","    return 'original'\n","\n","# def test_regression_forest(models, x_train_list, y_train_list, x_test, y_test, path_list, sufix):\n","\n","#     '''\n","#     Objetivo:\n","\n","#         - Implementar el modelo Regression Forest adaptado para una clasificación binaria\n","\n","#     Input:\n","\n","#         - models      : Diccionario que especifica el modelo de Regressión Forest y los parámetros de grid search.\n","#         - x_train_list: Lista de conjuntos de entrenamiento con las variables predictoras. La lista debe\n","#                         seguir el siguiente orden: Original, SMOTE, SMOTE Tomek-Links y Naive Random \n","#                         Oversampling. Ejemplo: x_train_list = [ x_train, x_train_s, x_train_st, x_train_nro ]\n","#         - y_train_list: Lista de conjuntos de entrenamiento con la variable predicha. La lista debe\n","#                         seguir el siguiente orden: Original, SMOTE, SMOTE Tomek-Links y Naive Random \n","#                         Oversampling. Ejemplo: y_train_list = [ y_train, y_train_s, y_train_st, y_train_nro ]\n","#         - x_test      : Conjunto de prueba con las variables predictoras\n","#         - y_test      : Cnjunto de prueba con la variable predicha\n","#         - path_list   : Lista de paths donde se guardarán los archivo output. Se asume que la lista de paths\n","#                         tendrá cuatro elementos, los cuales son: path en el que se guardan los modelos preentrenados\n","#                         (primero), path en el que se guardan las métricas de desempeño (segundo), path en el que se\n","#                         guardan las  listas de variables con importancia/coeficientes (tercero) y path en el que se \n","#                         guardan los resultados de grid search (cuarto). Se asume que se sigue el orden mencionado en \n","#                         paréntesis.\n","\n","#     Output:\n","\n","#         - resultados               : Pandas dataframe con las métricas de los distintos modelos implementados.\n","#         - modelos entrenados       : todos los modelos entrenados se guardan en formato joblib en el path \n","#                                      especificado\n","#         - lista de variables       : Listas de variables que muestra la importancia (en el caso de los métodos \n","#                                      basados en árboles) o coeficientes (en el caso de los métodos lineares) de \n","#                                      las variables predictoras. Se muestran en formato de tabla. \n","#         - resultados de grid search: Detalles sobre el ajuste del algoritmo de Grid Search. Se muestran en \n","#                                      formato de tabla.\n","                                     \n","#     '''\n","\n","#     threshold_range = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","\n","#     for path in path_list:\n","#         if not os.path.exists(path):\n","#             os.makedirs(path)\n","    \n","#     # Inicializar el ExcelWriter fuera del loop de thresholds\n","#     excel_path = f'{path_list[1]}/results_{sufix}_reg_forest_all_thresholds.xlsx'\n","#     with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n","#         for threshold in threshold_range:\n","#             results = {\n","                \n","#                 'Model'             : [],\n","                \n","#                 'accuracy_train'    : [],\n","#                 'log_loss_train'    : [],\n","#                 'roc_auc_train'     : [],\n","#                 'f1_train'          : [],\n","#                 'f1_train_si'       : [],\n","#                 'f1_train_no'       : [],        \n","#                 'MCC_train'         : [],               \n","                \n","#                 'accuracy_test'     : [],\n","#                 'log_loss_test'     : [],\n","#                 'roc_auc_test'      : [],\n","#                 'f1_test'           : [],\n","#                 'f1_test_si'        : [],\n","#                 'f1_test_no'        : [],        \n","#                 'MCC_test'          : [],\n","                \n","#                 'Grid_Search_Params': []\n","                \n","#             }\n","\n","#             for model_name, model_params in models.items():\n","#                 if 'model' not in model_params:\n","#                     raise ValueError(f'Model is not defined for {model_name}')\n","\n","#                 model = model_params['model']\n","#                 grid_params = model_params.get('grid_params', None)\n","\n","#                 for index, (x_train, y_train) in enumerate(zip(x_train_list, y_train_list)):\n","#                     train_suffix = extract_suffix( x_train.name ) \n","#                     pred_vars      = x_train.columns.to_list()\n","\n","#                     cv = KFold(n_splits=5, shuffle=True, random_state=2023)\n","#                     grid_search = GridSearchCV(model, grid_params, cv=cv, scoring='roc_auc')\n","#                     grid_search.fit(x_train, y_train)\n","#                     best_model = grid_search.best_estimator_\n","#                     best_params = grid_search.best_params_\n","\n","#                     # Calcular predicciones y métricas para el threshold actual\n","#                     y_pred_train_class = (best_model.predict(x_train) >= threshold).astype(int)\n","#                     y_pred_test_class = (best_model.predict(x_test) >= threshold).astype(int)\n","#                     y_pred_train_proba = best_model.predict(x_train)\n","#                     y_pred_test_proba = best_model.predict(x_test)\n","\n","#                     # Export models\n","#                     joblib.dump( best_model, f'{ path_list[ 0 ] }/model_{ sufix }_{ model_name }_{ train_suffix }.joblib' )\n","\n","#                     # Export features importance\n","#                     feature_importances = best_model.feature_importances_\n","#                     vars_df             = pd.DataFrame( {'Var': pred_vars, 'Importance Score': feature_importances } )\n","#                     vars_df             = vars_df.reindex( vars_df[ 'Importance Score' ].abs().sort_values( ascending = False ).index )\n","#                     vars_df.to_excel( f'{ path_list[ 2 ] }/varlist_{ sufix }_{ model_name }_{ train_suffix }.xlsx' )\n","\n","#                     # Agregar resultados al diccionario\n","#                     report_train = classification_report(y_train, y_pred_train_class, output_dict=True)\n","#                     report_test = classification_report(y_test, y_pred_test_class, output_dict=True)\n","                    \n","#                     # Calcular métricas para el conjunto de entrenamiento\n","#                     accuracy_train = accuracy_score(y_train, y_pred_train_class)\n","#                     log_loss_train = log_loss(y_train, y_pred_train_proba)  # Asegúrate de usar probabilidades aquí\n","#                     roc_auc_train = roc_auc_score(y_train, y_pred_train_proba)\n","#                     f1_score_train = f1_score(y_train, y_pred_train_class, average='macro')\n","#                     f1_score_train_si = report_train['1']['f1-score']  # Asumiendo que '1' representa la clase 'si'\n","#                     f1_score_train_no = report_train['0']['f1-score']  # Asumiendo que '0' representa la clase 'no'\n","#                     mcc_score_train = matthews_corrcoef(y_train, y_pred_train_class)\n","\n","#                     # Calcular métricas para el conjunto de pruebas\n","#                     accuracy_test = accuracy_score(y_test, y_pred_test_class)\n","#                     log_loss_test = log_loss(y_test, y_pred_test_proba) \n","#                     roc_auc_test = roc_auc_score(y_test, y_pred_test_proba)\n","#                     f1_score_test = f1_score(y_test, y_pred_test_class, average='macro')\n","#                     f1_score_test_si = report_test['1']['f1-score']  # Asumiendo que '1' representa la clase 'si'\n","#                     f1_score_test_no = report_test['0']['f1-score']  # Asumiendo que '0' representa la clase 'no'\n","#                     mcc_score_test = matthews_corrcoef(y_test, y_pred_test_class)\n","\n","#                     # Actualizar el diccionario de resultados\n","#                     results[ 'Model' ].append( f'{ model_name }_{ train_suffix }' )\n","                    \n","#                     results[ 'accuracy_train' ].append( round( accuracy_train, 3 ) )            \n","#                     results[ 'log_loss_train' ].append( round( log_loss_train, 3 ) )\n","#                     results[ 'roc_auc_train' ].append( round( roc_auc_train, 3 ) )\n","#                     results[ 'f1_train' ].append( round( f1_score_train, 3 ) )\n","#                     results[ 'f1_train_si' ].append( round( f1_score_train_si, 3 ) )\n","#                     results[ 'f1_train_no' ].append( round( f1_score_train_no, 3 ) )\n","#                     results[ 'MCC_train' ].append( round( mcc_score_train, 3 ) )               \n","                    \n","#                     results[ 'accuracy_test' ].append( round( accuracy_test, 3 ) )\n","#                     results[ 'log_loss_test' ].append( round( log_loss_test, 3 ) )\n","#                     results[ 'roc_auc_test' ].append( round( roc_auc_test, 3 ) )\n","#                     results[ 'f1_test' ].append( round( f1_score_test, 3 ) )\n","#                     results[ 'f1_test_si' ].append( round( f1_score_test_si, 3 ) )\n","#                     results[ 'f1_test_no' ].append( round( f1_score_test_no, 3 ) )   \n","#                     results[ 'MCC_test' ].append( round( mcc_score_test, 3 ) )   \n","                    \n","#                     results[ 'Grid_Search_Params' ].append( best_params ) \n","\n","#             # Convertir el diccionario de resultados a DataFrame\n","#             results_df_total = pd.DataFrame(results)\n","#             print(results_df_total)\n","#             results_df_total = results_df_total.sort_values( by = 'f1_test', ascending = False )\n","#             results_df_total.to_excel(writer, sheet_name=f'Threshold_{threshold}')"]},{"cell_type":"code","execution_count":67,"id":"de373b62","metadata":{},"outputs":[],"source":["def test_regression_forest(models, x_train_list, y_train_list, x_test, y_test, path_list, sufix):\n","\n","    '''\n","    Objetivo:\n","\n","        - Implementar el modelo Regression Forest adaptado para una clasificación binaria\n","\n","    Input:\n","\n","        - models      : Diccionario que especifica el modelo de Regressión Forest y los parámetros de grid search.\n","        - x_train_list: Lista de conjuntos de entrenamiento con las variables predictoras. La lista debe\n","                        seguir el siguiente orden: Original, SMOTE, SMOTE Tomek-Links y Naive Random \n","                        Oversampling. Ejemplo: x_train_list = [ x_train, x_train_s, x_train_st, x_train_nro ]\n","        - y_train_list: Lista de conjuntos de entrenamiento con la variable predicha. La lista debe\n","                        seguir el siguiente orden: Original, SMOTE, SMOTE Tomek-Links y Naive Random \n","                        Oversampling. Ejemplo: y_train_list = [ y_train, y_train_s, y_train_st, y_train_nro ]\n","        - x_test      : Conjunto de prueba con las variables predictoras\n","        - y_test      : Cnjunto de prueba con la variable predicha\n","        - path_list   : Lista de paths donde se guardarán los archivo output. Se asume que la lista de paths\n","                        tendrá cuatro elementos, los cuales son: path en el que se guardan los modelos preentrenados\n","                        (primero), path en el que se guardan las métricas de desempeño (segundo), path en el que se\n","                        guardan las  listas de variables con importancia/coeficientes (tercero) y path en el que se \n","                        guardan los resultados de grid search (cuarto). Se asume que se sigue el orden mencionado en \n","                        paréntesis.\n","\n","    Output:\n","\n","        - resultados               : Pandas dataframe con las métricas de los distintos modelos implementados.\n","        - modelos entrenados       : todos los modelos entrenados se guardan en formato joblib en el path \n","                                     especificado\n","        - lista de variables       : Listas de variables que muestra la importancia (en el caso de los métodos \n","                                     basados en árboles) o coeficientes (en el caso de los métodos lineares) de \n","                                     las variables predictoras. Se muestran en formato de tabla. \n","        - resultados de grid search: Detalles sobre el ajuste del algoritmo de Grid Search. Se muestran en \n","                                     formato de tabla.\n","                                     \n","    '''\n","\n","    columns   = [ 'no', 'si' ]\n","    threshold_range = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","\n","    for path in path_list:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","    \n","    results = {\n","        'Model'             : [],\n","        \n","        'accuracy_train'    : [],\n","        'log_loss_train'    : [],\n","        'roc_auc_train'     : [],\n","        'f1_train'          : [],\n","        'f1_train_si'       : [],\n","        'f1_train_no'       : [],        \n","        'MCC_train'         : [],               \n","        \n","        'accuracy_test'     : [],\n","        'log_loss_test'     : [],\n","        'roc_auc_test'      : [],\n","        'f1_test'           : [],\n","        'f1_test_si'        : [],\n","        'f1_test_no'        : [],        \n","        'MCC_test'          : [],\n","        \n","        'Grid_Search_Params': []\n","        \n","    }\n","\n","    for model_name, model_params in models.items():\n","        if 'model' not in model_params:\n","            raise ValueError(f'Model is not defined for {model_name}')\n","\n","        model = model_params['model']\n","        grid_params = model_params.get('grid_params', None)\n","\n","        for index, (x_train, y_train) in enumerate(zip(x_train_list, y_train_list)):\n","            train_suffix = extract_suffix( x_train.name ) \n","            pred_vars      = x_train.columns.to_list()\n","\n","            cv = KFold(n_splits=5, shuffle=True, random_state=2023)\n","            grid_search = GridSearchCV(model, grid_params, cv=cv, scoring='r2')\n","            grid_search.fit(x_train, y_train)\n","            best_model = grid_search.best_estimator_\n","            best_params = grid_search.best_params_\n","\n","            # Export models\n","            joblib.dump( best_model, f'{ path_list[ 0 ] }/model_{ sufix }_{ model_name }_{ train_suffix }.joblib' )\n","\n","            # Export Grid Search Results\n","            results_gs  = pd.DataFrame( grid_search.cv_results_ )\n","            results_gs.to_excel( f'{ path_list[ 3 ] }/gs_{ sufix }_{ model_name }_{ train_suffix }.xlsx' )\n","\n","            # Export features importance\n","            feature_importances = best_model.feature_importances_\n","            vars_df             = pd.DataFrame( {'Var': pred_vars, 'Importance Score': feature_importances } )\n","            vars_df             = vars_df.reindex( vars_df[ 'Importance Score' ].abs().sort_values( ascending = False ).index )\n","            vars_df.to_excel( f'{ path_list[ 2 ] }/varlist_{ sufix }_{ model_name }_{ train_suffix }.xlsx' )\n","\n","            y_pred_train_proba = best_model.predict(x_train)\n","            y_pred_test_proba = best_model.predict(x_test)\n","\n","            for threshold in threshold_range:\n","\n","                # Calcular predicciones y métricas para el threshold actual\n","                y_pred_train_class = (best_model.predict(x_train) >= threshold).astype(int)\n","                y_pred_test_class = (best_model.predict(x_test) >= threshold).astype(int)\n","\n","                # Agregar resultados al diccionario\n","                report_train = classification_report( y_train, y_pred_train_class, target_names = columns, output_dict = True )\n","                report_test = classification_report( y_test, y_pred_test_class, target_names = columns, output_dict = True )  \n","                \n","                # Calcular métricas para el conjunto de entrenamiento\n","                accuracy_train = accuracy_score(y_train, y_pred_train_class)\n","                log_loss_train = log_loss(y_train, y_pred_train_proba)\n","                roc_auc_train = roc_auc_score(y_train, y_pred_train_proba)\n","                f1_score_train = f1_score(y_train, y_pred_train_class, average='macro')\n","                f1_score_train_si = report_train['si']['f1-score']\n","                f1_score_train_no = report_train['no']['f1-score']\n","                mcc_score_train = matthews_corrcoef(y_train, y_pred_train_class)\n","\n","                # Calcular métricas para el conjunto de pruebas\n","                accuracy_test = accuracy_score(y_test, y_pred_test_class)\n","                log_loss_test = log_loss(y_test, y_pred_test_proba) \n","                roc_auc_test = roc_auc_score(y_test, y_pred_test_proba)\n","                f1_score_test = f1_score(y_test, y_pred_test_class, average='macro')\n","                f1_score_test_si = report_test['si']['f1-score']\n","                f1_score_test_no = report_test['no']['f1-score'] \n","                mcc_score_test = matthews_corrcoef(y_test, y_pred_test_class)\n","\n","                # Actualizar el diccionario de resultados\n","                results[ 'Model' ].append( f'{threshold}_{ model_name }_{ train_suffix }' )\n","                \n","                results[ 'accuracy_train' ].append( round( accuracy_train, 3 ) )            \n","                results[ 'log_loss_train' ].append( round( log_loss_train, 3 ) )\n","                results[ 'roc_auc_train' ].append( round( roc_auc_train, 3 ) )\n","                results[ 'f1_train' ].append( round( f1_score_train, 3 ) )\n","                results[ 'f1_train_si' ].append( round( f1_score_train_si, 3 ) )\n","                results[ 'f1_train_no' ].append( round( f1_score_train_no, 3 ) )\n","                results[ 'MCC_train' ].append( round( mcc_score_train, 3 ) )               \n","                \n","                results[ 'accuracy_test' ].append( round( accuracy_test, 3 ) )\n","                results[ 'log_loss_test' ].append( round( log_loss_test, 3 ) )\n","                results[ 'roc_auc_test' ].append( round( roc_auc_test, 3 ) )\n","                results[ 'f1_test' ].append( round( f1_score_test, 3 ) )\n","                results[ 'f1_test_si' ].append( round( f1_score_test_si, 3 ) )\n","                results[ 'f1_test_no' ].append( round( f1_score_test_no, 3 ) )   \n","                results[ 'MCC_test' ].append( round( mcc_score_test, 3 ) )   \n","                \n","                results[ 'Grid_Search_Params' ].append( best_params )  \n","\n","        # Convertir el diccionario de resultados a DataFrame\n","        results_df_total = pd.DataFrame(results)\n","        results_df_total = results_df_total.sort_values( by = 'f1_test', ascending = False )\n","\n","    return results_df_total"]},{"cell_type":"code","execution_count":68,"id":"1fce8db6","metadata":{},"outputs":[],"source":["# Regression Forest Model\n","\n","resultados_rf = test_regression_forest( models_regression_forest, x_train_list, y_train_list, x_test, y_test, path_list, sufix )\n","resultados_rf.to_excel( r'..\\..\\..\\output\\ejecucion_11\\results\\base0_ca_regression_forest.xlsx' )"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
